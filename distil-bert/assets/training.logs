CUDA Version: 11.8
Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33316/33316 [00:03<00:00, 8508.80 examples/s]
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3702/3702 [00:00<00:00, 8572.36 examples/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/sebastian/Documents/linea-enfasis/proyecto-integrador/mind-guard/distil-bert/venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
{'loss': 0.6048, 'grad_norm': 7.517540454864502, 'learning_rate': 1.903984637542007e-05, 'epoch': 0.24}
{'loss': 0.4065, 'grad_norm': 12.876056671142578, 'learning_rate': 1.8079692750840136e-05, 'epoch': 0.48}
{'loss': 0.3739, 'grad_norm': 4.817592620849609, 'learning_rate': 1.7119539126260203e-05, 'epoch': 0.72}
{'loss': 0.3542, 'grad_norm': 5.1525397300720215, 'learning_rate': 1.615938550168027e-05, 'epoch': 0.96}
{'loss': 0.3023, 'grad_norm': 3.260791540145874, 'learning_rate': 1.5199231877100338e-05, 'epoch': 1.2}
{'loss': 0.2835, 'grad_norm': 3.4485881328582764, 'learning_rate': 1.4239078252520404e-05, 'epoch': 1.44}
{'loss': 0.2866, 'grad_norm': 1.7948272228240967, 'learning_rate': 1.3278924627940472e-05, 'epoch': 1.68}
{'loss': 0.2754, 'grad_norm': 4.565989017486572, 'learning_rate': 1.231877100336054e-05, 'epoch': 1.92}
{'loss': 0.2348, 'grad_norm': 0.9224778413772583, 'learning_rate': 1.1358617378780605e-05, 'epoch': 2.16}
{'loss': 0.2037, 'grad_norm': 5.820087909698486, 'learning_rate': 1.0398463754200673e-05, 'epoch': 2.4}
{'loss': 0.2031, 'grad_norm': 9.740652084350586, 'learning_rate': 9.43831012962074e-06, 'epoch': 2.64}
{'loss': 0.2326, 'grad_norm': 7.1228227615356445, 'learning_rate': 8.478156505040807e-06, 'epoch': 2.88}
{'loss': 0.1812, 'grad_norm': 0.29724279046058655, 'learning_rate': 7.518002880460874e-06, 'epoch': 3.12}
{'loss': 0.1529, 'grad_norm': 8.614459991455078, 'learning_rate': 6.557849255880941e-06, 'epoch': 3.36}
{'loss': 0.1475, 'grad_norm': 0.8394620418548584, 'learning_rate': 5.597695631301009e-06, 'epoch': 3.6}
{'loss': 0.1592, 'grad_norm': 10.151834487915039, 'learning_rate': 4.637542006721076e-06, 'epoch': 3.84}
{'loss': 0.1383, 'grad_norm': 0.40600892901420593, 'learning_rate': 3.6773883821411425e-06, 'epoch': 4.08}
{'loss': 0.1134, 'grad_norm': 0.9223831295967102, 'learning_rate': 2.7172347575612103e-06, 'epoch': 4.32}
{'loss': 0.1097, 'grad_norm': 0.4526544511318207, 'learning_rate': 1.7570811329812771e-06, 'epoch': 4.56}
{'loss': 0.1165, 'grad_norm': 6.31718635559082, 'learning_rate': 7.969275084013443e-07, 'epoch': 4.8}
{'train_runtime': 4662.1074, 'train_samples_per_second': 35.731, 'train_steps_per_second': 2.234, 'train_loss': 0.23875787179171323, 'epoch': 5.0}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10415/10415 [1:17:42<00:00,  2.23it/s]
** Evaluation **
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 231/232 [00:34<00:00,  6.71it/s]/home/sebastian/Documents/linea-enfasis/proyecto-integrador/mind-guard/distil-bert/training/__main__.py:20: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  load_accuracy = load_metric("accuracy", trust_remote_code=True)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232/232 [00:35<00:00,  6.48it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232/232 [00:35<00:00,  6.53it/s]
